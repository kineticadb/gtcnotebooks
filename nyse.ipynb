{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Interacting with Kinetica vector similarity search via LLM\n",
    "### Install required packages"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4725d6feada17a62"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "!pip install gpudb==7.2.0.0b0 pandas pyarrow typeguard langchain langchain_openai nemollm==0.3.5 colorlog \"langchain-kinetica @ git+https://git@github.com/kineticadb/langchain-kinetica.git\""
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import kinetica.setup\n",
    "kinetica.setup.setup()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "44d95cbf6cebeaf1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Connect to Kinetica and the LLM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a772aad959674a7"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_kinetica import KineticaChatLLM, KineticaSqlOutputParser, SqlResponse\n",
    "\n",
    "#db = gpudb.GPUdb(host='https://demo72.kinetica.com/_gpudb',\n",
    "#                 username='gtc',\n",
    "#                 password='Kinetica123!')\n",
    "\n",
    "# create the Kinetica connection\n",
    "kdbc = KineticaChatLLM._create_kdbc(host=\"https://demo72.kinetica.com/_gpudb\", login=\"gtc\", password=\"Kinetica123!\")\n",
    "\n",
    "# create the Kinetica LLM\n",
    "kinetica_llm = KineticaChatLLM(kdbc=kdbc)\n",
    "\n",
    "# Set the context to use\n",
    "kinetica_ctx = 'nyse.nyse_vector_ctxt'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c901a1fbd82d73bb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Set up the context"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0fe527e9c06d9ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# load the context from the database\n",
    "ctx_messages = kinetica_llm.load_messages_from_context(kinetica_ctx)\n",
    "\n",
    "# Add the input prompt. This is where input question will be substituted.\n",
    "ctx_messages.append((\"human\", \"{input}\"))\n",
    "\n",
    "# Create the prompt template.\n",
    "prompt_template = ChatPromptTemplate.from_messages(ctx_messages)\n",
    "prompt_template.pretty_print()\n",
    "\n",
    "# create the chain. \n",
    "# note: The KineticaSqlOutputParser will execute the SQL statement and is optional.\n",
    "chain = prompt_template | kinetica_llm | KineticaSqlOutputParser(kdbc=kdbc)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf7eb0f3aae48fc3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some questions, including vector similarity search, without the SQL fuss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1499db800912c12"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Here you must ask a question relevant to the LLM context provided in the prompt template.\n",
    "response: SqlResponse = chain.invoke({\"input\": '''what stock has traded with the highest volume today?'''})\n",
    "display(HTML(response.dataframe.to_html(index=False)))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f3e07ae2376b4a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response: SqlResponse = chain.invoke({\"input\": '''find all sofi stock trades between 2024-01-29 14:25:00 and 2024-01-29 14:35:00 where the price is not null'''})\n",
    "response.dataframe.plot.line(x='t', y='lp')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d03aa4914d7fa2d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response: SqlResponse = chain.invoke({\"input\": '''find similar patterns to sofi at 2024-01-29 14:25:00.000'''})\n",
    "display(HTML(response.dataframe.to_html(index=False)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f7656b794ab418f",
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "response: SqlResponse = chain.invoke({\"input\": '''find all qqq stock trades between 2024-01-22 16:00:00 and 2024-01-22 16:05:00 where the price is not null'''})\n",
    "response.dataframe.plot.line(x='t', y='lp')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "275353076d998363",
   "execution_count": 0
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get Kinetica LLM and Nemo talking to each other"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb2cc0092e008529"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import importlib\n",
    "import kinetica.kineai\n",
    "\n",
    "importlib.reload(kinetica.kineai)\n",
    "kineticallm = kinetica.kineai.KineticaLLM('nyse.nyse_vector_ctxt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "363f78d91c80727a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "system = \"\"\" KineticAI is a cheerful AI assistant for engaging in a conversation between an LLM using the Nemo framework and the Kinetica LLM.  The Kinetica\n",
    "LLM is designed to translate natural language questions into SQL queries. \n",
    "\n",
    "In addition to responding with  natural language it is able to ask questions to a database AI named SqlAssist that can query and summarize the logs. \n",
    "If it responds with a \"KineticaLLM |  question\" where question is sent to the SqlAssist AI. The SqlAssist AI will respond with an answer \n",
    "to the question in JSON format to the question made to SqlAssist by KineticAI.\n",
    "\n",
    "when presented with a question, you should prefix your response with \"KineticaLLM | \"\n",
    "if a sentence ends in a \"?\", you should prefix your response with \"KineticaLLM | \"\n",
    "\n",
    "Consider the following example where a user asks KineticAI a question and KineticAI asks a followup question to SqlAssist. KineticAI uses the response from \n",
    "SqlAssist to answer the user's question.\n",
    "\n",
    "user: what is the weather like today?\n",
    "assistant: KineticaLLM | what is the weather like today?\n",
    "user: KineticaLLM |  [{\"EXPR_0\": 5.4}]\n",
    "assistant: The answer is 5.4\n",
    "\"\"\"\n",
    "\n",
    "context0 = [dict(role=\"system\", content=system),\n",
    "            dict(role=\"user\", content=\"what is the stock price today?\"),\n",
    "            dict(role=\"assistant\", content=\"KineticaLLM | what is the stock price today?\"),\n",
    "            dict(role=\"user\", content=\"how many rows of data are you storing?\"),\n",
    "            dict(role=\"assistant\", content=\"KineticaLLM | how many rows of data are you storing?\"),\n",
    "            dict(role=\"user\", content=\"what is the average number of telemetry rows per 5 second increment?\"),\n",
    "            dict(role=\"assistant\", content=\"KineticaLLM | what is the average number of telemetry rows per 5 second increment?\"),\n",
    "            dict(role=\"user\", content=\"find me top stock prices today\"),\n",
    "            dict(role=\"assistant\", content=\"KineticaLLM | find me top stock prices today\")]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bbbaacbd2b6a0ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "question = 'what stock symbol other than Apple has the highest price within the last 15 minutes?'\n",
    "response = kineticallm.chat(context0, question)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63f688a7efca6afb",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
